# Heart Failure Prediction Model - .pkl File Generation Code
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import pickle
import warnings
warnings.filterwarnings('ignore')

# Load the dataset from your uploaded file
df = pd.read_csv('heart_failure_clinical_records_dataset (1).csv')

print("Dataset shape:", df.shape)
print(f"Number of samples: {len(df)}")
print(f"Number of features: {len(df.columns) - 1}")

print("\nDataset columns:")
print(df.columns.tolist())

print("\nFirst few rows:")
print(df.head())

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

# Basic statistics
print("\nBasic statistics:")
print(df.describe())

# Check target distribution
print(f"\nTarget distribution:")
death_counts = df['DEATH_EVENT'].value_counts()
print(f"Survived (0): {death_counts[0]} ({death_counts[0]/len(df)*100:.1f}%)")
print(f"Death (1): {death_counts[1]} ({death_counts[1]/len(df)*100:.1f}%)")

# Check for any data quality issues
print(f"\nData quality check:")
print(f"Age range: {df['age'].min():.1f} - {df['age'].max():.1f}")
print(f"Ejection fraction range: {df['ejection_fraction'].min():.1f}% - {df['ejection_fraction'].max():.1f}%")
print(f"Follow-up time range: {df['time'].min()} - {df['time'].max()} days")

# Features and target
X = df.drop('DEATH_EVENT', axis=1)
y = df['DEATH_EVENT']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features for models that need scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train multiple models with optimized hyperparameters for this dataset
models = {
    'RandomForest': RandomForestClassifier(
        n_estimators=150, 
        max_depth=8, 
        min_samples_split=3,
        min_samples_leaf=2,
        max_features='sqrt',
        random_state=42
    ),
    'GradientBoosting': GradientBoostingClassifier(
        n_estimators=120,
        learning_rate=0.15,
        max_depth=4,
        min_samples_split=5,
        random_state=42
    ),
    'LogisticRegression': LogisticRegression(
        random_state=42,
        max_iter=1000,
        C=0.8
    )
}

best_accuracy = 0
best_model = None
best_model_name = ""
use_scaler = False

print("\nModel Performance:")
print("-" * 40)

for name, model in models.items():
    # Use scaled data for Logistic Regression
    if name == 'LogisticRegression':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        current_use_scaler = True
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        current_use_scaler = False
    
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{name}: {accuracy:.4f}")
    
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = model
        best_model_name = name
        use_scaler = current_use_scaler

print(f"\nBest Model: {best_model_name}")
print(f"Best Accuracy: {best_accuracy:.4f}")

# Final evaluation
if use_scaler:
    final_predictions = best_model.predict(X_test_scaled)
else:
    final_predictions = best_model.predict(X_test)

print(f"\nFinal Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, final_predictions):.4f}")

# Create model package for saving
model_package = {
    'model': best_model,
    'scaler': scaler if use_scaler else None,
    'use_scaler': use_scaler,
    'feature_names': list(X.columns),
    'model_name': best_model_name,
    'accuracy': best_accuracy
}

# Save model to .pkl file
with open('heart_failure_model.pkl', 'wb') as file:
    pickle.dump(model_package, file)

print(f"\nModel saved as 'heart_failure_model.pkl'")

# Verify the saved model works
print("\nTesting saved model...")
with open('heart_failure_model.pkl', 'rb') as file:
    loaded_package = pickle.load(file)

loaded_model = loaded_package['model']
loaded_scaler = loaded_package['scaler']
loaded_use_scaler = loaded_package['use_scaler']

# Test prediction with sample data
sample_data = X_test.iloc[0:1]
if loaded_use_scaler:
    sample_prediction = loaded_model.predict(loaded_scaler.transform(sample_data))
    sample_probability = loaded_model.predict_proba(loaded_scaler.transform(sample_data))
else:
    sample_prediction = loaded_model.predict(sample_data)
    sample_probability = loaded_model.predict_proba(sample_data)

print(f"Sample prediction: {sample_prediction[0]}")
print(f"Sample probability: {sample_probability[0]}")
print(f"Actual value: {y_test.iloc[0]}")

print(f"\nModel package contents:")
for key in loaded_package.keys():
    print(f"- {key}: {type(loaded_package[key])}")

print(f"\nFeature names: {loaded_package['feature_names']}")
print(f"Model successfully saved and tested!")

# Function to use in Flask app
def predict_heart_failure_from_pkl(age, anaemia, creatinine_phosphokinase, diabetes, 
                                  ejection_fraction, high_blood_pressure, platelets, 
                                  serum_creatinine, serum_sodium, sex, smoking, time):
    """
    Prediction function for Flask app
    """
    with open('heart_failure_model.pkl', 'rb') as file:
        model_package = pickle.load(file)
    
    model = model_package['model']
    scaler = model_package['scaler']
    use_scaler = model_package['use_scaler']
    
    # Create input array
    input_features = np.array([[
        age, anaemia, creatinine_phosphokinase, diabetes,
        ejection_fraction, high_blood_pressure, platelets,
        serum_creatinine, serum_sodium, sex, smoking, time
    ]])
    
    # Apply scaling if needed
    if use_scaler:
        input_features = scaler.transform(input_features)
    
    # Make prediction
    prediction = model.predict(input_features)[0]
    probability = model.predict_proba(input_features)[0]
    
    return prediction, probability

# Test the prediction function
print(f"\nTesting prediction function:")
test_pred, test_prob = predict_heart_failure_from_pkl(
    75, 0, 582, 0, 20, 1, 265000, 1.9, 130, 1, 0, 4
)
print(f"Test prediction: {test_pred}")
print(f"Test probabilities: {test_prob}")